#!/usr/bin/env python3
"""
Quick setup script for llama-cpp-python integration
Downloads a small test model and configures WhisperEngine to use it
"""

import os
import sys
import urllib.request
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def download_test_model():
    """Download a small GGUF model for testing"""
    models_dir = Path("./models")
    models_dir.mkdir(exist_ok=True)
    
    # Small efficient model for testing (~650MB)
    model_url = "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf"
    model_filename = "Phi-3-mini-4k-instruct-q4.gguf"
    model_path = models_dir / model_filename
    
    if model_path.exists():
        logger.info(f"‚úÖ Model already exists: {model_path}")
        return str(model_path)
    
    logger.info(f"üì• Downloading test model: {model_filename}")
    logger.info(f"   URL: {model_url}")
    logger.info(f"   Size: ~650MB (this may take a few minutes)")
    
    try:
        def progress_hook(block_num, block_size, total_size):
            downloaded = block_num * block_size
            if total_size > 0:
                percent = min(100, (downloaded * 100) // total_size)
                mb_downloaded = downloaded // (1024 * 1024)
                mb_total = total_size // (1024 * 1024)
                print(f"\r   Progress: {percent}% ({mb_downloaded}/{mb_total} MB)", end="", flush=True)
        
        urllib.request.urlretrieve(model_url, model_path, progress_hook)
        print()  # New line after progress
        logger.info(f"‚úÖ Download complete: {model_path}")
        return str(model_path)
        
    except Exception as e:
        logger.error(f"‚ùå Download failed: {e}")
        return None

def configure_environment(model_path):
    """Configure environment variables for llamacpp"""
    logger.info("üîß Configuring environment for llama-cpp-python...")
    
    # Create or update .env file
    env_file = Path(".env")
    env_lines = []
    
    # Read existing .env if it exists
    if env_file.exists():
        with open(env_file, 'r') as f:
            env_lines = f.readlines()
    
    # Update or add llamacpp configuration
    new_lines = []
    updated_url = False
    updated_path = False
    
    for line in env_lines:
        if line.startswith("LLM_CHAT_API_URL="):
            new_lines.append("LLM_CHAT_API_URL=llamacpp://local\n")
            updated_url = True
        elif line.startswith("LLAMACPP_MODEL_PATH="):
            new_lines.append(f"LLAMACPP_MODEL_PATH={model_path}\n")
            updated_path = True
        else:
            new_lines.append(line)
    
    # Add new lines if not updated
    if not updated_url:
        new_lines.append("LLM_CHAT_API_URL=llamacpp://local\n")
    if not updated_path:
        new_lines.append(f"LLAMACPP_MODEL_PATH={model_path}\n")
    
    # Write back to .env
    with open(env_file, 'w') as f:
        f.writelines(new_lines)
    
    logger.info(f"‚úÖ Updated {env_file} with llamacpp configuration")

def verify_installation():
    """Verify that llama-cpp-python is installed"""
    logger.info("üîç Checking llama-cpp-python installation...")
    
    try:
        import llama_cpp
        logger.info(f"‚úÖ llama-cpp-python is installed (version: {llama_cpp.__version__})")
        return True
    except ImportError:
        logger.error("‚ùå llama-cpp-python is not installed")
        logger.info("   Install with: source .venv/bin/activate && pip install llama-cpp-python")
        return False

def test_integration():
    """Test the integration by running our test script"""
    logger.info("üß™ Testing llama-cpp-python integration...")
    
    try:
        # Run the comprehensive success test instead
        result = os.system("source .venv/bin/activate && python test_llamacpp_success.py")
        if result == 0:
            logger.info("‚úÖ Integration test passed!")
            return True
        else:
            logger.error("‚ùå Integration test failed")
            return False
    except Exception as e:
        logger.error(f"‚ùå Failed to run integration test: {e}")
        return False

def main():
    print("üöÄ WhisperEngine llama-cpp-python Quick Setup")
    print("=" * 50)
    
    # Check installation
    if not verify_installation():
        return 1
    
    # Download model
    model_path = download_test_model()
    if not model_path:
        return 1
    
    # Configure environment
    configure_environment(model_path)
    
    # Test integration
    if not test_integration():
        return 1
    
    print("\nüéâ Setup complete! llama-cpp-python is ready to use.")
    print("\nNext steps:")
    print("1. Start WhisperEngine:")
    print("   source .venv/bin/activate && python universal_native_app.py")
    print("   OR (Discord bot):")
    print("   source .venv/bin/activate && python run.py")
    print("\n2. The AI will now use the optimized llama-cpp-python backend!")
    print("\n3. Benefits you'll notice:")
    print("   ‚Ä¢ Faster responses")
    print("   ‚Ä¢ Lower memory usage")
    print("   ‚Ä¢ No internet required")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())