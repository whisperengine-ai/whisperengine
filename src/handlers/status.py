"""
Status command handlers for Discord bot
Includes ping, bot status, LLM status, voice status, vision status, and cache stats
"""
import logging
import discord
from discord.ext import commands
import asyncio
import time
import os

logger = logging.getLogger(__name__)

class StatusCommandHandlers:
    """Handles status-related commands"""
    
    def __init__(self, bot, bot_name, llm_client, voice_manager, voice_support_enabled, 
                 VOICE_AVAILABLE, image_processor, conversation_history, conversation_cache, 
                 heartbeat_monitor):
        self.bot = bot
        self.bot_name = bot_name
        self.llm_client = llm_client
        self.voice_manager = voice_manager
        self.voice_support_enabled = voice_support_enabled
        self.VOICE_AVAILABLE = VOICE_AVAILABLE
        self.image_processor = image_processor
        self.conversation_history = conversation_history
        self.conversation_cache = conversation_cache
        self.heartbeat_monitor = heartbeat_monitor
    
    def register_commands(self, bot_name_filter):
        """Register all status commands"""
        
        # Capture self reference for nested functions
        status_handler_instance = self
        
        @self.bot.command(name='ping')
        @bot_name_filter()
        async def ping(ctx):
            """Simple ping command"""
            logger.debug(f"Ping command called by {ctx.author.name} in {ctx.channel.name if ctx.guild else 'DM'}")
            await ctx.send('Pong!')
        
        @self.bot.command(name='llm_status')
        @bot_name_filter()
        async def llm_status(ctx):
            """Check if the LLM server is running and show configuration"""
            await status_handler_instance._llm_status_handler(ctx)
        
        @self.bot.command(name='bot_status')
        @bot_name_filter()
        async def bot_status(ctx):
            """Check and refresh the bot's Discord presence"""
            await status_handler_instance._bot_status_handler(ctx)
        
        @self.bot.command(name='clear_chat')
        @bot_name_filter()
        async def clear_chat(ctx):
            """Clear the conversation history in this channel"""
            await status_handler_instance._clear_chat_handler(ctx)
        
        @self.bot.command(name='cache_stats')
        @bot_name_filter()
        async def cache_stats(ctx):
            """Show conversation cache statistics"""
            await status_handler_instance._cache_stats_handler(ctx)
        
        @self.bot.command(name='vision_status')
        @bot_name_filter()
        async def vision_status(ctx):
            """Check if the LLM supports vision (image processing)"""
            await status_handler_instance._vision_status_handler(ctx)
        
        @self.bot.command(name='voice_status')
        @bot_name_filter()
        async def voice_status(ctx):
            """Check voice support status and configuration"""
            await status_handler_instance._voice_status_handler(ctx)
        
        @self.bot.command(name='test_image')
        @bot_name_filter()
        async def test_image(ctx):
            """Test image processing with an attached image"""
            await status_handler_instance._test_image_handler(ctx)
    
    async def _llm_status_handler(self, ctx):
        """Handle LLM status command"""
        logger.debug(f"LLM status command called by {ctx.author.name}")
        
        embed = discord.Embed(
            title="ü§ñ LLM Server Status",
            color=0x27ae60 if self.llm_client.check_connection() else 0xe74c3c
        )
        
        if self.llm_client.check_connection():
            logger.info("LLM status check: Connected")
            embed.add_field(
                name="Connection Status",
                value="‚úÖ **Connected** - Server is running and responding",
                inline=False
            )
            
            # Show main service configuration
            api_key_status = "‚úÖ Configured" if self.llm_client.api_key else "‚ùå Not set"
            embed.add_field(
                name="ü§ñ Main Chat Service",
                value=f"‚Ä¢ Service: **{self.llm_client.service_name}**\n‚Ä¢ API URL: **{self.llm_client.api_url}**\n‚Ä¢ API Key: **{api_key_status}**\n‚Ä¢ Model: **{self.llm_client.default_model_name}**\n‚Ä¢ Max tokens: **{self.llm_client.default_max_tokens_chat:,}**",
                inline=False
            )
            
            # Show emotion analysis service configuration
            emotion_api_key_status = "‚úÖ Configured" if self.llm_client.emotion_api_key else "‚ùå Not set"
            emotion_same_endpoint = self.llm_client.emotion_api_url == self.llm_client.api_url
            emotion_info = "Same as main service" if emotion_same_endpoint else f"‚Ä¢ Service: **{self.llm_client.emotion_service_name}**\n‚Ä¢ API URL: **{self.llm_client.emotion_api_url}**\n‚Ä¢ API Key: **{emotion_api_key_status}**"
            
            embed.add_field(
                name="üòä Emotion Analysis Service",
                value=f"{emotion_info}\n‚Ä¢ Model: **{self.llm_client.emotion_model_name}**\n‚Ä¢ Max tokens (emotion): **{self.llm_client.max_tokens_emotion}**\n‚Ä¢ Max tokens (trust): **{self.llm_client.max_tokens_trust_detection}**",
                inline=False
            )

            # Show facts analysis service configuration
            facts_api_key_status = "‚úÖ Configured" if self.llm_client.facts_api_key else "‚ùå Not set"
            facts_same_endpoint = self.llm_client.facts_api_url == self.llm_client.api_url
            facts_info = "Same as main service" if facts_same_endpoint else f"‚Ä¢ Service: **{self.llm_client.facts_service_name}**\n‚Ä¢ API URL: **{self.llm_client.facts_api_url}**\n‚Ä¢ API Key: **{facts_api_key_status}**"
            
            embed.add_field(
                name="üìù Facts Analysis Service",
                value=f"{facts_info}\n‚Ä¢ Model: **{self.llm_client.facts_model_name}**\n‚Ä¢ Max tokens (facts): **{self.llm_client.max_tokens_fact_extraction}**\n‚Ä¢ Max tokens (personal): **{self.llm_client.max_tokens_personal_info}**\n‚Ä¢ Max tokens (user facts): **{self.llm_client.max_tokens_user_facts}**",
                inline=False
            )
            
            # Show timeout configuration
            embed.add_field(
                name="‚è±Ô∏è Timeout Configuration",
                value=f"‚Ä¢ Request timeout: **{self.llm_client.request_timeout}s**\n‚Ä¢ Connection timeout: **{self.llm_client.connection_timeout}s**",
                inline=False
            )
            
            # Show vision support
            vision_status = "‚úÖ Enabled" if self.llm_client.supports_vision else "‚ùå Disabled"
            vision_details = f"**{vision_status}**"
            if self.llm_client.supports_vision:
                vision_config = self.llm_client.get_vision_config()
                if vision_config and 'max_images' in vision_config:
                    vision_details += f"\n‚Ä¢ Max images: **{vision_config['max_images']}**"
            embed.add_field(
                name="Vision Support",
                value=vision_details,
                inline=False
            )
        else:
            logger.warning("LLM status check: Disconnected")
            embed.add_field(
                name="Connection Status",
                value="‚ùå **Disconnected** - Server is not responding",
                inline=False
            )
            # Different troubleshooting based on service type
            if self.llm_client.is_openrouter:
                troubleshooting = "‚Ä¢ Check your OPENROUTER_API_KEY is valid\n‚Ä¢ Verify your OpenRouter account has credits\n‚Ä¢ Ensure the model name is correct"
            else:
                troubleshooting = "‚Ä¢ Make sure your LLM provider (LM Studio/Ollama/etc.) is running\n‚Ä¢ Check that the server is accessible\n‚Ä¢ Verify the API endpoint configuration"
                
            embed.add_field(
                name="Troubleshooting",
                value=troubleshooting,
                inline=False
            )
        
        await ctx.send(embed=embed)
    
    async def _bot_status_handler(self, ctx):
        """Handle bot status command"""
        logger.debug(f"Bot status command called by {ctx.author.name}")
        
        embed = discord.Embed(
            title="ü§ñ Discord Bot Status",
            color=0x3498db
        )
        
        # Show current status
        if self.bot.user:
            embed.add_field(
                name="Bot Information",
                value=f"‚Ä¢ Bot Name: **{self.bot.user.name}#{self.bot.user.discriminator}**\n‚Ä¢ Bot ID: **{self.bot.user.id}**\n‚Ä¢ Connected Guilds: **{len(self.bot.guilds)}**",
                inline=False
            )
        else:
            embed.add_field(
                name="Bot Information",
                value=f"‚Ä¢ Bot User: **Not Available**\n‚Ä¢ Connected Guilds: **{len(self.bot.guilds)}**",
                inline=False
            )
        
        # Try to refresh presence
        try:
            await self.bot.change_presence(status=discord.Status.online)
            await asyncio.sleep(0.5)  # Small delay
            activity = discord.Activity(type=discord.ActivityType.listening, name="...")
            await self.bot.change_presence(status=discord.Status.online, activity=activity)
            
            embed.add_field(
                name="Presence Status",
                value="‚úÖ **Online** - Presence refreshed successfully",
                inline=False
            )
            
            logger.info(f"Bot presence refreshed by {ctx.author.name}")
            
        except Exception as e:
            embed.add_field(
                name="Presence Status",
                value=f"‚ùå **Error** - Failed to set presence: {str(e)}",
                inline=False
            )
            logger.error(f"Failed to refresh bot presence: {e}")
        
        # Add heartbeat monitor status
        if self.heartbeat_monitor:
            heartbeat_status = self.heartbeat_monitor.get_status()
            if heartbeat_status['running']:
                hb_text = f"‚úÖ **Running** - Monitor active\n‚Ä¢ Last heartbeat: {time.strftime('%H:%M:%S', time.localtime(heartbeat_status['last_heartbeat'])) if heartbeat_status['last_heartbeat'] else 'N/A'}\n‚Ä¢ Bot latency: {heartbeat_status['bot_latency']:.3f}s\n‚Ä¢ Connection issues: {heartbeat_status['connection_issues']}"
            else:
                hb_text = "‚ùå **Stopped** - Monitor not running"
            
            embed.add_field(
                name="ü´Ä Heartbeat Monitor",
                value=hb_text,
                inline=False
            )

        # Add troubleshooting info
        embed.add_field(
            name="If bot still appears offline:",
            value="‚Ä¢ Try refreshing Discord (Ctrl+R)\n‚Ä¢ Restart your Discord client\n‚Ä¢ Check bot permissions in server settings\n‚Ä¢ Wait 1-2 minutes for Discord to update",
            inline=False
        )
        
        await ctx.send(embed=embed)
    
    async def _clear_chat_handler(self, ctx):
        """Handle clear chat command"""
        logger.info(f"Clear chat command called by {ctx.author.name} in {ctx.channel.name if ctx.guild else 'DM'}")
        channel_id = str(ctx.channel.id)
        
        # Clear both old conversation history and new cache
        if self.conversation_history:
            self.conversation_history.clear_channel(channel_id)
        if self.conversation_cache:
            self.conversation_cache.clear_channel_cache(channel_id)
        
        logger.debug(f"Cleared conversation history and cache for channel {channel_id}")
        
        await ctx.send("‚úÖ Conversation history has been cleared.")
    
    async def _cache_stats_handler(self, ctx):
        """Handle cache stats command"""
        if not self.conversation_cache:
            await ctx.send("‚ùå Conversation cache is not available.")
            return
        
        # Handle both sync (HybridConversationCache) and async (RedisConversationCache) stats
        try:
            # Import to check the type
            from src.memory.redis_conversation_cache import RedisConversationCache
            
            if isinstance(self.conversation_cache, RedisConversationCache):
                stats = await self.conversation_cache.get_cache_stats()
            else:
                # Default to sync method
                stats = self.conversation_cache.get_cache_stats()
                
        except Exception as e:
            await ctx.send(f"‚ùå Failed to get cache stats: {str(e)}")
            return
        
        embed = discord.Embed(
            title="üíæ Conversation Cache Statistics",
            color=0x3498db
        )
        
        # Handle both old and new cache stat formats
        cached_channels = stats.get('cached_channels', stats.get('channels_cached', 0))
        total_messages = stats.get('total_cached_messages', stats.get('total_messages', 0))
        avg_messages = stats.get('avg_messages_per_channel', 0)
        
        embed.add_field(
            name="üìä Cache Usage",
            value=f"‚Ä¢ Cached channels: **{cached_channels}**\n"
                  f"‚Ä¢ Total cached messages: **{total_messages}**\n"
                  f"‚Ä¢ Avg messages/channel: **{avg_messages:.1f}**",
            inline=False
        )
        
        embed.add_field(
            name="‚öôÔ∏è Cache Configuration",
            value=f"‚Ä¢ Cache timeout: **{stats.get('cache_timeout_minutes', 0):.0f} minutes**\n"
                  f"‚Ä¢ Bootstrap limit: **{stats.get('bootstrap_limit', 0)} messages**\n"
                  f"‚Ä¢ Max local messages: **{stats.get('max_local_messages', 0)} per channel**",
            inline=False
        )
        
        embed.add_field(
            name="üöÄ Performance Benefits",
            value="‚Ä¢ Reduces Discord API calls by ~90%\n"
                  "‚Ä¢ Faster response times for active conversations\n"
                  "‚Ä¢ Automatic cache refresh when stale",
            inline=False
        )
        
        await ctx.send(embed=embed)
    
    async def _vision_status_handler(self, ctx):
        """Handle vision status command"""
        logger.debug(f"Vision status command called by {ctx.author.name}")
        
        vision_config = self.llm_client.get_vision_config()
        
        # Handle case where vision_config might be None
        supports_vision = vision_config and vision_config.get('supports_vision', False)
        
        embed = discord.Embed(
            title="üñºÔ∏è Vision Support Status",
            color=0x3498db if supports_vision else 0x95a5a6
        )
        
        if supports_vision:
            embed.add_field(
                name="Status",
                value="‚úÖ **Enabled** - The bot can process image attachments",
                inline=False
            )
            max_images = vision_config.get('max_images', 'Unknown') if vision_config else 'Unknown'
            embed.add_field(
                name="Configuration",
                value=f"‚Ä¢ Max images per message: **{max_images}**\n‚Ä¢ Supported formats: **JPG, PNG, GIF, WebP, BMP**\n‚Ä¢ Max image size: **10MB**\n‚Ä¢ Max dimensions: **2048x2048**",
                inline=False
            )
            embed.add_field(
                name="How to use",
                value="Simply attach images to your messages when chatting with the bot in DMs or when mentioning the bot in channels.",
                inline=False
            )
        else:
            embed.add_field(
                name="Status",
                value="‚ùå **Disabled** - Vision support is not available",
                inline=False
            )
            embed.add_field(
                name="Note",
                value="The bot will describe attached images in text instead of processing them visually.",
                inline=False
            )
            embed.add_field(
                name="Configuration",
                value="To enable vision support, set `LLM_SUPPORTS_VISION=true` in your environment configuration.",
                inline=False
            )
        
        await ctx.send(embed=embed)
    
    async def _voice_status_handler(self, ctx):
        """Handle voice status command"""
        logger.debug(f"Voice status command called by {ctx.author.name}")
        
        # Determine voice support status
        voice_available = self.VOICE_AVAILABLE
        voice_enabled = self.voice_support_enabled
        has_voice_manager = self.voice_manager is not None
        
        embed = discord.Embed(
            title="üé§ Voice Support Status",
            color=0x3498db if (voice_available and voice_enabled and has_voice_manager) else 0x95a5a6
        )
        
        if voice_available and voice_enabled and has_voice_manager:
            embed.add_field(
                name="Status",
                value="‚úÖ **Enabled** - Voice functionality is fully operational",
                inline=False
            )
            embed.add_field(
                name="Available Features",
                value="‚Ä¢ Text-to-speech responses\n‚Ä¢ Voice channel connections\n‚Ä¢ Voice commands (!join, !leave, !speak)\n‚Ä¢ Connection keepalive system\n‚Ä¢ @mention voice responses",
                inline=False
            )
            embed.add_field(
                name="Configuration",
                value=f"‚Ä¢ ElevenLabs API: {'‚úÖ Connected' if self.voice_manager else '‚ùå Not configured'}\n‚Ä¢ Auto-join: {'‚úÖ Enabled' if os.getenv('VOICE_AUTO_JOIN', 'false').lower() == 'true' else '‚ùå Disabled'}\n‚Ä¢ Voice responses: {'‚úÖ Enabled' if os.getenv('VOICE_RESPONSE_ENABLED', 'true').lower() == 'true' else '‚ùå Disabled'}",
                inline=False
            )
            embed.add_field(
                name="How to use",
                value="Use `!join` to connect to voice channel, then @mention the bot for voice responses or use `!speak <text>` for TTS.",
                inline=False
            )
        elif voice_available and not voice_enabled:
            embed.add_field(
                name="Status",
                value="‚öôÔ∏è **Disabled by Configuration** - Dependencies available but disabled",
                inline=False
            )
            embed.add_field(
                name="How to enable",
                value="Set `VOICE_SUPPORT_ENABLED=true` in your .env file and restart the bot.",
                inline=False
            )
            embed.add_field(
                name="Available when enabled",
                value="‚Ä¢ Text-to-speech responses\n‚Ä¢ Voice channel connections\n‚Ä¢ Voice commands\n‚Ä¢ ElevenLabs integration",
                inline=False
            )
        else:
            embed.add_field(
                name="Status",
                value="‚ùå **Unavailable** - Missing dependencies or configuration",
                inline=False
            )
            embed.add_field(
                name="Requirements",
                value="‚Ä¢ PyNaCl (Discord voice): `pip install PyNaCl`\n‚Ä¢ ElevenLabs client: `pip install elevenlabs`\n‚Ä¢ Valid ElevenLabs API key\n‚Ä¢ FFmpeg installed on system",
                inline=False
            )
            embed.add_field(
                name="Configuration needed",
                value="‚Ä¢ Set `VOICE_SUPPORT_ENABLED=true`\n‚Ä¢ Add `ELEVENLABS_API_KEY` to .env\n‚Ä¢ Install required dependencies",
                inline=False
            )
        
        embed.set_footer(text="Use !voice_help for voice commands when enabled")
        await ctx.send(embed=embed)
    
    async def _test_image_handler(self, ctx):
        """Handle test image command"""
        logger.debug(f"Test image command called by {ctx.author.name}")
        
        if not ctx.message.attachments:
            embed = discord.Embed(
                title="üì∑ Test Image Processing",
                description="Please attach an image to this command to test image processing capabilities.",
                color=0xe67e22
            )
            embed.add_field(
                name="Usage",
                value="```!test_image``` with an image attached",
                inline=False
            )
            embed.add_field(
                name="Supported formats",
                value="JPG, PNG, GIF, WebP, BMP",
                inline=True
            )
            embed.add_field(
                name="Max size",
                value="10MB",
                inline=True
            )
            await ctx.send(embed=embed)
            return
        
        # Process the attachments
        if self.image_processor:
            processed_images = await self.image_processor.process_multiple_attachments(ctx.message.attachments)
        else:
            processed_images = []
        
        if not processed_images:
            await ctx.send("‚ùå No valid images found in your attachments.")
            return
        
        embed = discord.Embed(
            title="üñºÔ∏è Image Processing Test Results",
            color=0x27ae60
        )
        
        for i, img in enumerate(processed_images, 1):
            embed.add_field(
                name=f"Image {i}: {img['filename']}",
                value=f"‚Ä¢ Format: **{img['format'].upper()}**\n‚Ä¢ Size: **{img['size']:,} bytes**\n‚Ä¢ Status: ‚úÖ **Processed successfully**",
                inline=False
            )
        
        vision_config = self.llm_client.get_vision_config()
        if vision_config and vision_config.get('supports_vision', False):
            embed.add_field(
                name="Vision Support",
                value="‚úÖ **Available** - These images can be sent to the LLM for analysis",
                inline=False
            )
        else:
            embed.add_field(
                name="Vision Support",
                value="‚ùå **Not available** - Images will be described in text only",
                inline=False
            )
        
        embed.set_footer(text=f"Processed {len(processed_images)} of {len(ctx.message.attachments)} attachments")
        
        await ctx.send(embed=embed)